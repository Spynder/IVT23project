В начале мы рассмотрели независимую вероятность: вероятность события $A$. Условная вероятность, как следует из названия, добавляет условие - событие, что уже произошло. Благодаря этому знанию, вероятность события $A$ *может* измениться.

Условная вероятность события $A$ при условии происхождения события $B$ записывается следующим образом:
$$P(A|B) = \frac{P(AB)}{P(B)}$$
По определению, условная вероятность - это отношение вероятности происхождения событий вместе $P(AB)$ к вероятности происхождения события-условия $P(B)$.

Обычную вероятность можно было представить как отношение площади события $A$ к площади всего вероятностного пространства $\Omega$:
![[probability/3-1.png]]

Условная вероятность смещает вероятностное пространство - нам уже точно известно, что событие $B$ произошло, и $\Omega$ переходит в $B$. Среди всех оставшихся возможностей, какая вероятность, что произойдет $A$? От $A$ остался только кусочек $AB$:
![[probability/3-2.png]]

## Независимые события
События $A$ и $B$ называются *парно независимыми*, если наступление одного из событий не меняет вероятность другого:
$$\array{P(A|B) = P(A) \\ P(B|A) = P(B)}$$
Определение условной вероятности можно записать и следующим образом:
$$P(A|B)P(B) = P(AB) = P(B|A)P(A)$$
Отсюда видно, что если верны первые два условия, то и следующее условие верно (подстановка):
$$P(A)P(B) = P(AB)$$
Аналогично определение расширяется и до *совокупной* независимости: для любого подмножества $I$ событий $\set{A_1, \ldots, A_n}$ произведение их вероятностей должно равняться вероятности наступления всех событий вместе:
$$\prod_{A \in I} P(A) = P\left(\bigcap_{A \in I} A\right)$$
Из совокупной независимости следует парная, но из парной не следует совокупная! (См. тетраэдр Бернштайна)

Полезное свойство у независимых событий, что если множество событий совокупно независимо, то и множества с их дополнениями (отрицаниями) тоже совокупно независимо:
$$\array{P(A_1A_2A_3A_4A_5) = P(A_1)P(A_2)P(A_3)P(A_4)P(A_5)& \Rightarrow \\ P(A_1A_2\overline{A_3}A_4\overline{A_5}) = P(A_1)P(A_2)P(\overline{A_3})P(A_4)P(\overline{A_5})&}$$
## Формула сложения
Вероятность происхождения хотя бы одного из событий $A$ и $B$ равна:
$$P(A + B) = P(A) + P(B) - P(AB)$$
Геометрический смысл наследуется со смысла формулы включений-исключений с множествами. Как и с ней, формулу можно обобщить до скольки угодно событий, просто подставляя одну в другую:
$$\array{P(A+B+C) = P((A+B)+C) = P(A+B) + P(C) - P((A+B)C) = \\ = P(A+B) + P(C) - P(AC+BC) = \ldots}$$
## Несовместные события
События $A$ и $B$ называются несовместными, если они не могут произойти вместе...буквально:
$$P(AB) = 0$$
Тогда из формулы сложения мы получаем, что если события несовместны, то:
$$P(A+B) = P(A) + P(B)$$
Причем не существует возможных (вероятность события выше нуля) несовместных событий, которые так же будут независимы!

---

Подведем итоги по независимым и несовместным событиям: их можно легко определять через формулы сложения и умножения. Если $A$ и $B$ независимы, то
$$P(AB) = P(A)P(B)$$
Если $A$ и $B$ несовместны, то
$$P(A+B) = P(A) + P(B)$$
## Формула полной вероятности
Дано событие $A$, и пусть дана система гипотез $\set{H_i}$ о событии $A$, что образуют полную группу (это значит, что гипотезы между собой несовместны и какая-то из гипотез будет верна: $\sum_i P(H_i) = 1$).

Тогда вероятность события $A$ можно посчитать по формуле полной вероятности:
$$P(A) = \sum_{i=1}^n P(H_i) P(A|H_i)$$
Вывод формулы элементарный:
$$A = \bigcup_{i=1}^n H_i A \Rightarrow P(A) = \sum_{i=1}^n P(H_iA) = \sum_{i=1}^n P(H_i) P(A|H_i)$$
## Формула Байеса
Формула Байеса помогает найти вероятность события, при условии происхождения какого-то другого события. В частности, оно помогает найти вероятность происхождения какой-то гипотезы $H_k$, при условии выполнения основного события $A$.

Совмещая определение условной вероятности и формулу полной вероятности, можно получить формулу Байеса. По определению:
$$P(H_k)P(A|H_k) = P(A)P(H_k|A)$$
Если поделим обе стороны уравнения на $A$, то получим формулу Байеса:
$$P(H_k|A) = \frac{P(H_k)P(A|H_k)}{P(A)}$$
При желании, можно подставить вниз формулу полной вероятности:
$$P(H_k|A) = \frac{P(H_k)P(A|H_k)}{\sum\limits_{i=1}^n P(H_i) P(A|H_i)}$$

Как отличить задачу на полную вероятность от задачи на формулу Байеса?
- Обычно, в задачах на полную вероятность спрашивают "найдите вероятность события, если ...".
- В задачах на формулу Байеса спрашивают "событие произошло. Найдите вероятность, что была верна гипотеза $i$".